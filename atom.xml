<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>没想好</title>
  
  
  <link href="//atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-12-13T13:31:24.750Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Jialin Hou</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>article-title</title>
    <link href="http://yoursite.com/2019/12/13/article-title/"/>
    <id>http://yoursite.com/2019/12/13/article-title/</id>
    <published>2019-12-13T13:25:06.156Z</published>
    <updated>2019-12-13T13:31:24.750Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>General Metagenome pipeline</title>
    <link href="http://yoursite.com/2019/12/13/General%20Metagenome%20pipeline(houjialin6-20191019122533)/"/>
    <id>http://yoursite.com/2019/12/13/General%20Metagenome%20pipeline(houjialin6-20191019122533)/</id>
    <published>2019-12-13T13:25:06.000Z</published>
    <updated>2019-12-13T13:43:10.058Z</updated>
    
    <content type="html"><![CDATA[<p>The paired-end metagenomic reads is packed as two compressed files, like 00_input-1.fq and 00_input-2.fq, after received from sequencing company.</p><h2 id="1-The-quality-control-of-raw-data"><a href="#1-The-quality-control-of-raw-data" class="headerlink" title="1.  The quality control of raw data"></a>1.  The quality control of raw data</h2><p>First of all, we should access the quality of raw reads using FastQC to identify the possible contamination, despite the company claimed the feedback reads are high quality and adapter-free metagenome. </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Access the quality of raw reads with FastQC</span></span><br><span class="line">fastqc ./00_input-1.fq ./00_input-2.fq</span><br></pre></td></tr></table></figure><p>There are 12 modules analyzed based on the quality of reads, please pay attention to those marked with waring or fail. The common reason of each waring and failed modules you can find in the office website of <a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/" target="_blank" rel="noopener">FastQC</a>. Here,  only discuss some understanding of myself, just for reference. </p><ol><li><strong>Basic statistics</strong>: this module never raise a waring and failed<ul><li>Encoding: Phred encoding system of reads, Phred + 64 for Illumina 1.3/1.5+; Phred +33 for Illumina 1.8+. Ours is 1.5+ so that is Phred +64 encoding system. Metagenome of our lab is sequenced by BGI of Huada Gene company through HiSeq 2500 (2018-9-14). </li></ul></li><li><strong>Per Base Sequence Quality</strong>:  the range of quality values across all bases at each position in the FastQ file<ul><li>The quality of base usually is bad at the beginning and tail of a read due to the unstable start status of sequencing platform and the sequencing chemistry degradation with the read length. Based on our sample, we think the low quality base at beginning position looks more common. </li></ul></li><li><strong>Per Sequence Quality Scores</strong>: The average base quality of read at each position.  <ul><li>The variation of quality shown in this module indicates the existence of systematic problem. Usually not</li></ul></li><li><strong>Per Base Sequence Content</strong>: The average of GC proportion of read at each position.<ul><li>Overrepresented sequence will raise a significant variation in this plot.</li><li>Biased fragmentation always occurs at the first 12bp of each run.</li><li>Sodium bisulphite will cause compositional bias. </li><li>Aggressive trimming will  cause content bias at the end of reads due to the remain of adapter that not be removed clearly.</li></ul></li><li><strong>Per Sequence GC content</strong>: The GC content across the whole length of each read and compared with normal distribution.<ul><li>An unusually shaped distribution could indicate a contaminated library or some other kinds of biased subset</li><li>Usually means some problem in the library building. </li><li>Sharp peaks indicates the potential contamination of overrepresented sequence, like adapter.</li></ul></li><li><h2 id="Overrepresented-sequences-sequence-which-make-up-over-0-1"><a href="#Overrepresented-sequences-sequence-which-make-up-over-0-1" class="headerlink" title="Overrepresented sequences: sequence which make up over 0.1%"></a><strong>Overrepresented sequences</strong>: sequence which make up over 0.1%</h2></li></ol><h2 id="2-Trmming"><a href="#2-Trmming" class="headerlink" title="2. Trmming"></a>2. Trmming</h2><p>Using Trimmomatic to remove the possible adaptor and and low quality bases of every reads.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line">time nohup java -jar /software/Software/Trimmomatic-0.38/trimmomatic-0.38.jar PE -threads 10 ../00_raw_data/01_sickled_1.fastq.gz ../00_raw_data/01_sickled_2.fastq.gz -baseout 02_trimmed_reads.fq.gz ILLUMINACLIP:/software/Software/Trimmomatic-0.38/adapters/TruSeq3-PE.fa:2:30:10:1:ture SLIDINGWINDOW:4:15 MINLEN:50&amp;</span><br></pre></td></tr></table></figure><blockquote><p>ILLUMINACLIP:<fastaWithAdaptersEtc>:<seed mismatches>:<palindrome clip threshold>:<simple clip threshold>:<minAdapterLength>:<keepBothReads></p><p>ILLUMINACLIP:TruSeq3-SE:2:30:10 #接头和引物序列在 TruSeq3-SE 中，第一步 seed 搜索允许2个碱基错配，palindrome 比对分值阈值 30，simple clip 比对分值阈值 10，palindrome 模式允许切除的最短接头序列为 8bp（默认值），palindrome 模式去除与 R1 完全反向互补的 R2（默认去除）</p><p>-PE/SE</p><p>​    设定对Paired-End或Single-End的reads进行处理，其输入和输出参数稍有不一样。<br>-threads<br>​    设置多线程运行数<br>-phred33<br>​    设置碱基的质量格式，可选pred64<br>ILLUMINACLIP:TruSeq3-PE.fa:2:30:10<br>​    切除adapter序列。参数后面分别接adapter序列的fasta文件：允许的最大mismatch<br>数：palindrome模式下匹配碱基数阈值：simple模式下的匹配碱基数阈值。<br>LEADING:3<br>​    切除首端碱基质量小于3的碱基<br>TRAILING:3<br>​    切除尾端碱基质量小于3的碱基<br>SLIDINGWINDOW:4:15<br>​    从5’端开始进行滑动，当滑动位点周围一段序列(window)的平均碱基低于阈值，则从该处进行切除。Windows的size是4个碱基，其平均碱基<br>质量小于15，则切除。<br>MINLEN:50<br>​    最小的reads长度<br>CROP:<length><br>​    保留reads到指定的长度<br>HEADCROP:<length><br>​    在reads的首端切除指定的长度<br>TOPHRED33<br>​    将碱基质量转换为pred33格式<br>TOPHRED64<br>​    将碱基质量转换为pred64格式</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># estimate the sequecing quality (phred 33 or 64)</span></span></span><br><span class="line">perl /home/houjialin/data/sdl/perl_script/xiao_yuan_perl/fastq_phred_decide.pl Mariana.trench.8600.IS300_Clean.1.fq.gz</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># trimming (default quiality is 20, min length is 20)</span></span></span><br><span class="line">nohup sickle pe -f Mariana.trench.8600.IS300_Clean.1.fq.gz -r Mariana.trench.8600.IS300_Clean.2.fq.gz -t illumina -o 01_trimmed_1.fastq -p 01_trimmed_2.fastq -s 01_trimmed_deleted.fastq &amp;</span><br></pre></td></tr></table></figure><h3 id="2-Coverage-of-metagenome"><a href="#2-Coverage-of-metagenome" class="headerlink" title="2. Coverage of metagenome"></a>2. Coverage of metagenome</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">activate Nonpareil</span><br><span class="line"></span><br><span class="line">nohup nonpareil -s ../02_trimmed_reads_1P.fq -t 20 -T kmer -f fastq -b output&amp;</span><br></pre></td></tr></table></figure><h2 id="2-Assemble"><a href="#2-Assemble" class="headerlink" title="2. Assemble"></a>2. Assemble</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> MEGAHIT (recommanded)</span></span><br><span class="line">nohup megahit -t 20 -m 0.2 --min-count 2 --k-min 41 --kmin-1pass --k-max 147 --k-step 10 -1 ../01_trimming/02_trimmed_reads_1P.fq.gz -2 ../01_trimming/02_trimmed_reads_2P.fq.gz -o megahit&amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> IDBA-UD</span></span><br><span class="line">nohup idba_ud -o 03_idba_ud --mink 52 --maxk 92 --step 6 --num_threads 50 -r 02_merged.fasta &amp;</span><br></pre></td></tr></table></figure><p>After the finishing of assemble, remove the </p><blockquote><ol><li></li><li>For IDBA-UD, please change the -r to -l when the length of reads is more than 128 bp, do not use the -l when your length of reads less than the 128 bp, which could cause unpredictable error !</li></ol></blockquote><h2 id="3-Mapping"><a href="#3-Mapping" class="headerlink" title="3. Mapping"></a>3. Mapping</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> seMquence more than 1K bp</span></span><br><span class="line">perl -ne 'if(/&gt;/)&#123;$id=$_;$seq=&lt;&gt;;if(length($seq)&gt;500)&#123;print "$id$seq"&#125;&#125;' ../03_assembly.fasta &gt;11_500_sequence.fasta</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> build bowtiew2 index</span></span><br><span class="line">nohup bowtie2-build 11_500_sequence.fasta 01_sequence_build &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> mapping with bowtie2</span></span><br><span class="line">nohup bowtie2 --very-sensitive --non-deterministic --no-unal -p 40 --reorder -x 01_sequence_build -1 ../01_trimmed_1.fastq -2 ../01_trimmed_2.fastq -S 02_trimmed_to_assembly.sam &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> achieve depth info of each contig</span></span><br><span class="line">nohup cytoscapeviz -f 1 -i 02_trimmed_to_assembly.sam&amp;</span><br><span class="line">perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/coverage_count.pl</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">######## Transfer to the format required for binning #######################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> tansfer to jgi depth format (For MetaBat2 and Maxbin)</span></span><br><span class="line">perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/cytoscapeviz_2_metabat2_depth.pl</span><br><span class="line">perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/cytoscapeviz_2_maxbin_depth.pl</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">################ Other command involved Mapping ##############################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Transfer sam 2 bam</span></span><br><span class="line">nohup samtools view -bS 02_trimmed_to_assembly.sam &gt; 02_trimmed_to_assembly.bam&amp;</span><br><span class="line"></span><br><span class="line">rm -f ./02_trimmed_to_assembly.sam</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> sort and index the bam </span></span><br><span class="line"> nohup samtools sort 1000_trimmed_to_assembly.bam -o 1000_trimmed_to_assembly.sort.bam&amp;</span><br><span class="line"> nohup samtools index 1000_trimmed_to_assembly.sort.bam&amp;</span><br></pre></td></tr></table></figure><h2 id="4-ORF-prediction-and-Annotation"><a href="#4-ORF-prediction-and-Annotation" class="headerlink" title="4. ORF prediction and Annotation"></a>4. ORF prediction and Annotation</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> prediction &amp; translation (&gt;1K) </span></span><br><span class="line">nohup prodigal -i ../../03_assembly/total_1000_sequence.fasta -d ORF.1k.fasta -p meta -a protein.1k.faa -f gff -o genes_predicted.gff&amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Formating</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> For nucltide sequence</span></span><br><span class="line">perl -i.bak -pe's/(&gt;k127_\d+_\d+)\s.*/$1/g' Q1-ORF.fasta</span><br><span class="line">perl ~/data/sdl/perl_script/hou_meta_pipeline/trans_fasta_2_one_line.pl Q1-ORF.fasta ORF</span><br><span class="line">mv ORF Q1-ORF.fasta</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> For amino acid sequence</span></span><br><span class="line">perl -i.bak -pe's/(&gt;k127_\d+_\d+)\s.*/$1/g' Q1-protein.fasta</span><br><span class="line">perl ~/data/sdl/perl_script/hou_meta_pipeline/trans_fasta_2_one_line.pl Q1-protein.fasta PRO</span><br><span class="line">mv PRO Q1-protein.fasta</span><br><span class="line">perl -i.bak -pe's/\*//g' Q1-protein.fasta</span><br><span class="line">rm -f *.bak</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Overall Annotation <span class="keyword">in</span> NOG</span></span><br><span class="line">source activate py27</span><br><span class="line">nohup emapper.py  -i ./Q3-protein.fasta --cpu 10 --seed_ortholog_evalue 0.00001 -m diamond -o total_1k.annotation.tsv&amp;</span><br><span class="line">source deactivate</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Predict the specific genes based on hmm model</span></span><br><span class="line">hmmsearch /home/houjialin/data/Database/Custom_HMM_DB/rbcL/HMM/rbcL-1.hmm /home/houjialin/data/sdl/07_M_vent_Metagenome/23_gene_prediction/total_1000_protein.faa &gt; rbcL-1.hmmsearch.tsv</span><br></pre></td></tr></table></figure><h2 id="5-Relative-abundance-of-functional-gene"><a href="#5-Relative-abundance-of-functional-gene" class="headerlink" title="5. Relative abundance of functional gene"></a>5. Relative abundance of functional gene</h2><ul><li><p>Account the depth of each functional gene predicted in the metagenome</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Input:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1. depth file (maxbin format)</span></span><br><span class="line"><span class="meta">#</span><span class="bash">2. total protein file </span></span><br><span class="line"><span class="meta">#</span><span class="bash">3. gene ID file (rbcL.uniq.id )</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Method:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> proportion of depth <span class="built_in">times</span> length <span class="keyword">for</span> each gene <span class="keyword">in</span> the total genes,</span></span><br><span class="line"></span><br><span class="line">perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Genes/gene_relative_abundance.pl ../../../../../41_read_depth/depth_for_maxbin_coassembly/depth_for_maxbin.txt ../../../../../23_gene_prediction/total_1000_protein.faa ./ascB.id.txt ascB.uniq.tsv</span><br></pre></td></tr></table></figure></li></ul><h2 id="5-TPM-of-functional-gene"><a href="#5-TPM-of-functional-gene" class="headerlink" title="5. TPM of functional gene"></a>5. TPM of functional gene</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> make sure the contig id of depth file is consistent with the ORF files</span></span><br><span class="line">perl ~/data/sdl/perl_script/hou_meta_pipeline/TPM/TPM_value.pl ../../41_read_depth/depth_for_maxbin_coassembly/depth_for_maxbin.txt ./ORF.1k.fasta gene-TPM.tsv</span><br><span class="line"></span><br><span class="line">perl ~/data/sdl/perl_script/hou_meta_pipeline/TPM/TPM_for_genes.pl ../../23_gene_prediction/GFF/gene-TPM.tsv ./Nitrogen.id Nitrogen-TPM.tsv</span><br></pre></td></tr></table></figure><h2 id="6-Taxonomic-assignment-of-functional-genes"><a href="#6-Taxonomic-assignment-of-functional-genes" class="headerlink" title="6. Taxonomic assignment of functional genes"></a>6. Taxonomic assignment of functional genes</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> get the amino acid sequences</span></span><br><span class="line">perl ~/data/sdl/perl_script/hou_meta_pipeline/TPM/TPM_value.pl ../depth_for_maxbin_coassembly/depth_for_maxbin.txt ../../05_annotation/Q2-ORF.fasta gene-TPM.tsv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> diamond <span class="keyword">in</span> the NR DB</span></span><br><span class="line">nohup diamond blastp --db /software/DataBase/NR_2017_03_04/nr_mod_with_taxonomy -p 20 -q ./PRK.faa --query-cover 50 -e 1e-10 -k 1 -o PRK.NR.tsv&amp;</span><br></pre></td></tr></table></figure><p>##5. 16S rRNA gene prediction</p><p>Predict the 16S rRNA gene in the contigs &gt; 1K. Cutoff: the length &gt; 300bp and bitscore &gt; 300.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cmsearch</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> For bacteria</span></span><br><span class="line">nohup cmsearch -o bacteria.txt -A bacteria.fasta --cpu 50 /software/DataBase/cm/bacteria.cm ../scaffold.fa&amp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> For archaea</span></span><br><span class="line">nohup cmsearch -o archaea.txt -A archaea.fasta --cpu 50 /software/DataBase/cm/archaea.cm ../scaffold.fa&amp;</span><br></pre></td></tr></table></figure><h2 id="6-Kaiju"><a href="#6-Kaiju" class="headerlink" title="6. Kaiju"></a>6. Kaiju</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nohup kaijux -z 10 -t /software/DataBase/KaijuDB/nr.Bac_Arc_Vir/nodes.dmp -f  /software/DataBase/KaijuDB/nr.Bac_Arc_Vir/kaiju_db_nr.fmi -i ../01_trimming/02_trimmed_reads_1P.fq.gz -j ../01_trimming/02_trimmed_reads_2P.fq.g -o kaiju.out&amp;</span><br><span class="line"></span><br><span class="line">kaiju2krona -t /software/DataBase/KaijuDB/nr.Bac_Arc_Vir/nodes.dmp -n /software/DataBase/KaijuDB/nr.Bac_Arc_Vir/names.dmp -i kaiju.out -o kaiju.out.krona</span><br><span class="line"></span><br><span class="line">ktImportText -o kaiju.out.html kaiju.out.krona</span><br></pre></td></tr></table></figure><h3 id="6-MetaPhlan2"><a href="#6-MetaPhlan2" class="headerlink" title="6. MetaPhlan2"></a>6. MetaPhlan2</h3><hr><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> mapping</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line">nohup bowtie2 --sam-no-hd --sam-no-sq --no-unal --very-sensitive -S metagenome.sam -x /software/Software/metaphlan2/metaphlan_databases/mpa_v20_m200 -p 30 -1 ../01_trimming/02_trimmed_reads_1P.fq.gz -2 ../01_trimming/02_trimmed_reads_2P.fq.gz &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line">nohup /software/Software/metaphlan2/metaphlan2.py metagenome.sam --input_type sam &gt; profiled_metagenome.txt&amp;</span><br></pre></td></tr></table></figure><h2 id="7-Automatic-Binning"><a href="#7-Automatic-Binning" class="headerlink" title="7. Automatic Binning"></a>7. Automatic Binning</h2><p>For the medium- and low-complexity data sets, MaxBin 2.0 had the highest values (70–80%<br>completeness, &gt;92% purity), followed by other programs with comparably good performance in a narrow range (completeness ranging with one exception from 50–64%, &gt;75% purity). Notably, other programs assigned a larger portion of the data sets than MaxBin 2.0 measured in bp, though with lower adjusted Rand index (ARI; Fig.<br>2a). For applications where binning a larger fraction of the data set at the cost of some accuracy is important, MetaWatt 3.5, MetaBAT and CONCOCT could be good choices. The high-complexity data set was more challenging to all programs, with average completenessdecreasing to ~50% and more than 70% purity, except for MaxBin 2.0 and MetaWatt 3.5, which showed purity of above 90%. <em>[Critical Assessment of metagenome interpretation—a benchmark of metagenomics software]</em></p><h3 id="MetaBAT2"><a href="#MetaBAT2" class="headerlink" title="MetaBAT2"></a>MetaBAT2</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir 04_Binning &amp;&amp; cd 04_Binning</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> MetaBat2</span></span><br><span class="line">nohup metabat2 -i ../../02_assembly/megahit/total_1000_sequence.fasta -a ../../03_mapping/jgi_depth_sort.txt -o ./metabat2_bins -v &amp; </span><br><span class="line"></span><br><span class="line">nohup metabat2 -t 10 -i ../../../02_assembly/megahit/total_1000_sequence.fasta -a ../../../03_mapping/jgi_depth_sort.txt -o ./bins -v -m 5000&amp;</span><br></pre></td></tr></table></figure><blockquote><ul><li><strong>recall</strong> is completeness and <strong>precision</strong> = (1 - contamination) </li><li>The default length of contig used for binning is 2.5k, which could be reset by -m.  If initial results looked great, using more data (e.g. –minContig 1500) might be helpful to improve completeness of genome bins at the cost of some contamination.</li><li>We consider contigs for binning when they have at least one &gt;= minCV coverage (called effective coverage) in any samples and sum of effective coverage &gt;= minCVSum. Currently the default is both minCV and minCVSum are 1.</li><li>maxP sets the upper limit for deciding contigs in binning consideration by their quality in TNF (Tetra Nucleotide Frequency) score. So –maxP 95 means that it assumes at least 5% is noise. In reality, noise might be much higher, but it is safe to set this high since we have internal lower limit (pTNF = 70) preventing unnecessary build-up of TNF graph.</li><li>maxEdges is another way to control complexity of TNF graph where we limit the maximum number of edges per node by their strength (e.g. –maxEdges 200 means top 200 edges over the threshold, which is decided automatically by maxP, will be kept at most).</li><li>Lastly, minS is for cutoff in probability for combined score (SCR) graph building.</li><li></li></ul></blockquote><h3 id="MaxBin"><a href="#MaxBin" class="headerlink" title="MaxBin"></a>MaxBin</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perl /software/Software/MaxBin-2.2.1/run_MaxBin.pl -contig ./11_total_sequence.fasta -abund ./abdance.txt -thread 20 -plotmarker -markerset 40 -out Bins</span><br></pre></td></tr></table></figure><h3 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h3><p>The Criteria of merging Bins:</p><ol><li>The completeness increased by ≥ 10% and the contamination increased by ≤ 5% after merging<ol><li>The merged completeness &gt; 50% and contamination &lt; 10%.</li></ol></li><li>the mean GC of the bins were within <strong>5%</strong>, the mean coverage of the bins had an absolute percentage difference ≤ 25%</li><li>had identical taxonomic classifications as determined by their placement in the reference genome tree</li></ol><blockquote><p>The ‘merge’ method of CheckM v.1.0.6 was used to identify pairs of bins where the completeness increased by ≥ 10% and the contamination increased by ≤ 1% when merged into a single bin. Bins meeting these criteria were grouped into a single bin if the mean GC of the bins were within 3%, the mean coverage of the bins had an absolute percentage difference ≤ 25%, and the bins had identical taxonomic classifications as determined by their placement in the reference genome tree used by CheckM. This set of criteria was used to avoid producing chimaeric bins.</p></blockquote><p>​                                                                        ——– Gene W. Tyson</p><blockquote><p>Identifies genome bins with complementary sets of marker genes. Merging such bins will result in a notable increase in completeness with only a marginal, or no, increase in contamination. Caution must be exercised before merging two bins. To identify complementary sets of marker genes, a common set of markers must be sought after in each bin. We generally consider both the bacterial and archaeal sets produced by the <code>taxon_set</code> command. It is entirely possible that two bins will have complementary sets of marker genes, but should not be merged. We have observed this situation many times. Additional information should be used to confirm the merging of bins. We only merge bins after verifying that they have similar genomic characteristics (e.g., GC, coverage) and are placed in similar locations within a reference genome tree. This information is available using the <code>qa</code> and <code>tree_qa</code> commands, respectively.</p></blockquote><p>​                                                                        ——— CheckM manul</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">mkdir merge</span><br><span class="line"><span class="meta">#</span><span class="bash"> 建立细菌和古菌的marker <span class="built_in">set</span></span></span><br><span class="line">checkm taxon_set domain Bacteria ./merge/Bacteria</span><br><span class="line">checkm taxon_set domain Archaea ./merge/Archaea</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 对鉴定为细菌的bin进行merge</span></span><br><span class="line">nohup checkm merge -t 10 -x fa ./merge/Bacteria ./ ./merge/Bacteria_merge&amp;</span><br><span class="line">nohup checkm merge -t 10 -x fa ./merge/Archaea ./ ./merge/Archaea_merge&amp;</span><br></pre></td></tr></table></figure><blockquote><p>默认参数</p><ul><li>–delta_comp DELTA_COMP： minimum increase in completeness to report pair (default: 5.0)<br>–delta_cont DELTA_CONT： maximum increase in contamination to report pair (default: 10.0)<br>–merged_comp MERGED_COMP： minimum merged completeness to report pair (default: 50.0)<br>–merged_cont MERGED_CONT： maximum merged contamination to report pair (default: 20.0)</li></ul><p>阈值个人认为可以调低一点，因为后续的步骤可以去除污染序列，即降低污染度</p></blockquote><p>需要对可能需要merge的bin进行进一步判断，将GC，coverage和进化位置类似的bin合并</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出分类信息</span></span><br><span class="line">checkm tree_qa ./checkM &gt; Tree_qa.txt</span><br></pre></td></tr></table></figure><h3 id="RefineM"><a href="#RefineM" class="headerlink" title="RefineM"></a>RefineM</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">source activate py27</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> signature of scaffold</span></span><br><span class="line">nohup refinem scaffold_stats -x fasta -c 20 ../../../02_assembly/megahit/total_1000_sequence.fasta ./ ./stats_output ../../../03_mapping/1000_trimmed_to_assembly.sort.bam&amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Refine based on compositional heterogeneity</span></span><br><span class="line">mkdir 1_filtered_based_on_CS &amp;&amp; cd 1_filtered_based_on_CS</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> gene prediction of bins</span></span><br><span class="line">nohup refinem call_genes -x fasta -c 20 ../ ./gene_called&amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> refine bins based on compositional heterogeneity</span></span><br><span class="line">  nohup refinem outliers --no_plots ../stats_output/scaffold_stats.tsv ./outliers_out&amp;</span><br><span class="line"></span><br><span class="line">refinem filter_bins -x fasta ../ ./outliers_out/outliers.tsv ./outliter_filtered</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Refine based on taxnomoic classification</span></span><br><span class="line">cd ..</span><br><span class="line">mkdir 2_filtered_based_on_Taxa &amp;&amp; cd 2_filtered_based_on_Taxa</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> gene prediction of bins</span></span><br><span class="line">nohup refinem call_genes -x fasta -c 20 ../1_filtered_based_on_CS/outliter_filtered/ ./gene_called&amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> taxonomic classfication of scaffolds</span></span><br><span class="line">nohup refinem taxon_profile -c 20 ./gene_called ../stats_output/scaffold_stats.tsv  /home/houjialin/data/Database/refinem_DB/gtdb_r80_protein_db.2017-11-09.faa /home/houjialin/data/Database/refinem_DB/gtdb_r80_taxonomy.2017-12-15.tsv ./taxon_profile_output&amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> filter the contigs with distinct taxonomic classification</span></span><br><span class="line">refinem taxon_filter -c 20 ./taxon_profile_output/ ./taxon_filter_output&amp;</span><br><span class="line"></span><br><span class="line">refinem filter_bins -x fasta ../1_filtered_based_on_CS/outliter_filtered/  ./taxon_filter_output ./2_taxon_filtered</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">source deactivate py27</span><br></pre></td></tr></table></figure><h3 id="DAStools"><a href="#DAStools" class="headerlink" title="DAStools"></a>DAStools</h3><p>整合多个binning工具（或者参数）的分装结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> scaffold to bin</span></span><br><span class="line">/home/houjialin/Software/DAS_Tool/src/Fasta_to_Scaffolds2Bin.sh -e fasta -i ./ &gt; Maxbin.scaffold2bin_1k.tsv </span><br><span class="line"></span><br><span class="line">nohup /home/houjialin/Software/DAS_Tool/DAS_Tool.sh -i ./Maxbin.scaffold2bin_2k-v.tsv,MetaBat.scaffold2bin_2k.tsv -l maxbin_2k-v,metabat_2k -c ../../02_assembly/megahit/total_1000_sequence.fasta -o ./ -t 20 --write_bins &amp;</span><br></pre></td></tr></table></figure><h2 id="8-Quality-standards-of-MAGs"><a href="#8-Quality-standards-of-MAGs" class="headerlink" title="8.   Quality standards of MAGs"></a>8.   Quality standards of MAGs</h2><table><thead><tr><th align="center">Criterion</th><th align="center">Completeness</th><th align="center">Contamination</th><th align="center">Description</th></tr></thead><tbody><tr><td align="center">High quality</td><td align="center">&gt;90%</td><td align="center">&lt;5%</td><td align="center">23S,16S,5S rRNA gene and &gt;18 tRNAs</td></tr><tr><td align="center">Medium quality</td><td align="center">&gt;=50%</td><td align="center">&lt;10%</td><td align="center"></td></tr><tr><td align="center">Low quality</td><td align="center">&lt;50%</td><td align="center">&lt;10%</td><td align="center"></td></tr></tbody></table><h2 id="9-Evaluation-of-MAGs"><a href="#9-Evaluation-of-MAGs" class="headerlink" title="9. Evaluation of MAGs"></a>9. Evaluation of MAGs</h2><h4 id="确定目标基因组和Reference基因组"><a href="#确定目标基因组和Reference基因组" class="headerlink" title="确定目标基因组和Reference基因组"></a>确定目标基因组和Reference基因组</h4><p>目标和参考基因组尽量选择完整度较高的bin或者全基因组，否则38个保守蛋白可能缺失太多，影响最后的系统发育树的准确性。</p><h4 id="使用CheckM预处理"><a href="#使用CheckM预处理" class="headerlink" title="使用CheckM预处理"></a>使用CheckM预处理</h4><p>使用CheckM主要有3个目的：</p><ol><li>对建树基因组的质量进行评估。</li><li>使用内置Prodigal 预测ORF</li><li>翻译蛋白序列</li></ol><p><strong>将/checkM/bins/中各个bin的蛋白序列以其基因组命名拷贝至上册目录</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perl &#x2F;home&#x2F;houjialin&#x2F;data&#x2F;sdl&#x2F;perl_script&#x2F;hou_meta_pipeline&#x2F;Binning&#x2F;copy_bin_AA_from_checkM.pl</span><br></pre></td></tr></table></figure><blockquote><p>执行目录：checkM/bins</p></blockquote><p><strong>执行checkM</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py27</span><br><span class="line">nohup checkm lineage_wf -t 20 -x fa ./ ./checkM &amp;</span><br></pre></td></tr></table></figure><p><strong>提取bin的基本信息，在checkM执行文件夹中执行</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">checkm qa ./checkM/lineage.ms ./checkM/ -o 2 -f bin_quality.txt</span><br></pre></td></tr></table></figure><p><strong>基本信息绘图(完整度，污染度)</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">checkm bin_qa_plot--image_type pdf -x fa ./checkM/ ./ ./plot</span><br></pre></td></tr></table></figure><p><strong>GC</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">checkm gc_plot-x fa  --image_type pdf ./bin_test/./plot/ 95</span><br><span class="line">source deactivate</span><br></pre></td></tr></table></figure><p><strong>拷贝所有bin的蛋白文件到上层目录</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Binning/copy_bin_AA_from_checkM.pl</span><br></pre></td></tr></table></figure><blockquote><p>在checkM/bins 中执行</p></blockquote><p>将基因组翻译后的蛋白序列（ e.g <code>checkM/bins/L_bin189/gene.faa</code>）, 修改为对应的物种名，并以<code>faa</code>为后缀。全部放入指定文件夹如<code>./genomes</code>.</p><h4 id="进行38CSCG蛋白序列的比对，align，degap和串联"><a href="#进行38CSCG蛋白序列的比对，align，degap和串联" class="headerlink" title="进行38CSCG蛋白序列的比对，align，degap和串联"></a>进行38CSCG蛋白序列的比对，align，degap和串联</h4><p><code>perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/CSCG_phylogenetic_analysis/Phylogenetic_analysis_of_38_CSCG_pipeline.pl</code></p><h4 id="手动调整degap-alignment"><a href="#手动调整degap-alignment" class="headerlink" title="手动调整degap alignment"></a>手动调整degap alignment</h4><h4 id="构建系统发育树"><a href="#构建系统发育树" class="headerlink" title="构建系统发育树"></a>构建系统发育树</h4><ul><li>Fastree</li></ul><p><code>FastTree2.1.9 -wag  alignment.file  &gt; tree_file</code></p><ul><li>RaxML</li></ul><p><code>nohup raxmlHPC-PTHREADS -f a -x 12345 -p 12345 -# 1000 -m PROTGAMMAAUTO -T 40 -s 07_align_degap.phy -n aln.fna.phy.raxml&amp;</code></p><p><code>nohup raxmlHPC -m PROTGAMMAAUTO -p 12345 -f b -t RAxML_bestTree.aln.fna.phy.raxml -z RAxML_bootstrap.aln.fna.phy.raxml -n RAxML_bestbootstrap.aln.fna.phy.raxml.tre&amp;</code></p><p>####注意事项：</p><ul><li><p>首先确定diamond，clustalOmega，trimal 是否都已经安装并可以直接调用（已加入全局环境变量），如没有可以先尝试 <code>source /etc/profile</code> ，如还未成功请联系管理员。</p></li><li><p>COG注释的cutoff : bitscore&gt;100，对于同一个基因组含有2个以上相同的marker 蛋白的情况，选取bitscore最大的。</p></li><li><p>所有参与建树的蛋白序列必须以faa结尾，否则脚本不能识别。</p></li><li><p>38 CSCG COG数据库位置：<code>/home/houjialin/data/Database/38_CSCG/38_CSCG_protein_based_COG.faa</code>，使用特异的库可以加快比对速度，此外，发现原始的COG数据库可能存在问题</p></li></ul><h3 id="Genomic-Quality"><a href="#Genomic-Quality" class="headerlink" title="Genomic Quality"></a>Genomic Quality</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup checkm lineage_wf -t 10 -x fa ./ ./checkM &amp;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> count the coverage of each contig </span></span><br><span class="line">nohup checkm coverage -x fasta -t 10 -r ./ coverage.tsv../../../03_mapping/1000_trimmed_to_assembly.sort.bam &amp;</span><br></pre></td></tr></table></figure><p><strong>提取bin的基本信息，在checkM执行文件夹中执行</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> without coverage info</span></span><br><span class="line">checkm qa ./checkM/lineage.ms ./checkM/ -o 2 -f bin_quality.txt</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> with coverage info</span></span><br><span class="line">checkm qa ./checkM/lineage.ms ./checkM/ -o 2 -c ./coverage.tsv -f bin_quality.txt</span><br></pre></td></tr></table></figure><p> <strong>单独绘制系统发育树并输出分类信息</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">checkm tree_qa ./checkM &gt; Tree_qa.txt</span><br></pre></td></tr></table></figure><h3 id="16S-rRNA-gene"><a href="#16S-rRNA-gene" class="headerlink" title="16S rRNA gene"></a><strong>16S rRNA gene</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup checkm ssu_finder -x fa -t 20 -e 1e-10 ../../../02_assembly/megahit/total_2000_sequence.fasta ./ ./ssu_finder&amp;</span><br></pre></td></tr></table></figure><p><strong>Classify taxonomy of MAG</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir Annotation</span><br><span class="line"></span><br><span class="line">nohup time blastn -db /software/DataBase/SILVA_132_update-2018-10/00_silva132.nr99 -evalue 1e-10 -max_target_seqs 20 -num_threads 25 -outfmt '6 std qcovs qcovhsp' -out SSU_blastn_SILVA_128.txt -query ../ssu.fna &amp;</span><br><span class="line"></span><br><span class="line">nohup time blastn -db /software/DataBase/SILVA_132_update-2018-10/00_silva132.nr99 -evalue 1e-10 -max_target_seqs 1 -num_threads 25 -outfmt '6 std qcovs qcovhsp' -out SSU_blastn_SILVA_128_besthit.txt -query ../ssu.fna &amp;</span><br></pre></td></tr></table></figure><blockquote><p>Build database</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">nohup makeblastdb -<span class="keyword">in</span> nt -parse_seqids -hash_index -dbtype nucl -logfile nt_logfile &amp;</span></span><br></pre></td></tr></table></figure></blockquote><p><strong>Depth of MAG</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir Depth &amp;&amp; cd Depth</span><br><span class="line"></span><br><span class="line">/home/houjialin/Software/DAS_Tool/src/Fasta_to_Scaffolds2Bin.sh -e fa -i ../ &gt; DAS.scaffold2bin_2k.tsv</span><br><span class="line"></span><br><span class="line">perl -i.bak -lane'print"$F[0]\t$F[4]"' DAS.scaffold2bin_2k.tsv</span><br><span class="line"></span><br><span class="line">nohup perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Bins_average_depth.pl DAS.scaffold2bin_2k.tsv ../../../../03_mapping/depth_for_maxbin_coassembly/depth_for_maxbin_1_to_3.txt depth_for_1-3.tsv&amp;</span><br></pre></td></tr></table></figure><p><strong>基本信息绘图(完整度，污染度)</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">checkm bin_qa_plot --image_type pdf -x fa ./checkM/ ./ ./plot</span><br></pre></td></tr></table></figure><p><strong>GC</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">checkm gc_plot-x fa  --image_type pdf ./bin_test/./plot/ 95</span><br></pre></td></tr></table></figure><p><strong>拷贝所有bin的蛋白文件到上层目录</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Binning/copy_bin_AA_from_checkM.pl</span><br></pre></td></tr></table></figure><blockquote><p>在checkM/bins 中执行</p></blockquote><h2 id="10-Relative-abundance-of-MAG-in-multi-samples"><a href="#10-Relative-abundance-of-MAG-in-multi-samples" class="headerlink" title="10. Relative abundance of MAG in multi-samples"></a>10. Relative abundance of MAG in multi-samples</h2><p>Depth = (Depth * length) of bins’ contig / (Depth * length) of total contig</p><ul><li><pre><code class="shell">mdkir Depth &amp;&amp; cd Depth <span class="meta">#</span><span class="bash"> For example : evaluate the abundance of Bins recovered from Meta 1 <span class="keyword">in</span> the Meta 2.</span><span class="meta">#</span><span class="bash">      Four parameters: </span><span class="meta">#</span><span class="bash">        1. Scaffold<span class="string">'s ID of each bins</span></span><span class="meta">#</span><span class="bash">        2. depth file of meta2 reads mapping to meta1<span class="string">'s contig</span></span><span class="meta">#</span><span class="bash">        3. depth file of meta2 reads mapping to itself</span><span class="meta">#</span><span class="bash">        4. Length of each contig ()</span><span class="meta">#</span><span class="bash">         5. output file name</span>/home/houjialin/Software/DAS_Tool/src/Fasta_to_Scaffolds2Bin.sh -e fasta -i ./ &gt; Maxbin.scaffold2bin_1k.tsv nohup perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Bins_average_depth.pl DAS.scaffold2bin.tsv ../../../../03_mapping/depth_for_maxbin_coassembly/depth_for_maxbin_2-1.txt ../../../../03_mapping/depth_for_maxbin_coassembly/depth_for_maxbin.txt ../../../../03_mapping/cytoscape.length.tab depth_of_bins_2-1.tsv&amp;<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;- Please note the 4th file must be the depth for all contigs binned (like 3k), it will be underestimate the relative abundance of MAGs if you use the shorter contig (like 1k)  </span><br><span class="line">&gt;- Extract the depth of contigs with specific ID (e.g we have the ID of 3k contig, we can use this script to find their depth in the 1k contig&#39;s depth file</span><br><span class="line">&gt;  - perl &#x2F;home&#x2F;houjialin&#x2F;data&#x2F;sdl&#x2F;perl_script&#x2F;hou_meta_pipeline&#x2F;Depth 3k.ID.txt 1K.depth.txt</span><br><span class="line">&gt;  - Format: ID\tDepth</span><br><span class="line"></span><br><span class="line">## 11. Annotation</span><br><span class="line"></span><br><span class="line">### eggNOG，COG和KEGG数据库 和 Hydrogenase 数据库</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;shell</span><br><span class="line">## 批量注释</span><br><span class="line">nohup perl &#x2F;home&#x2F;houjialin&#x2F;data&#x2F;sdl&#x2F;perl_script&#x2F;hou_meta_pipeline&#x2F;Batch_annotation&#x2F;Batch_annotate_eggNOG_and_HyDB.pl ..&#x2F;Protein&#x2F; &amp;</span><br><span class="line">## 提取HyDB注释的BEST HIT</span><br><span class="line">perl &#x2F;home&#x2F;houjialin&#x2F;data&#x2F;sdl&#x2F;perl_script&#x2F;hou_meta_pipeline&#x2F;Batch_annotation&#x2F;Batch_diamond_best_hit.pl</span><br><span class="line">————————————————————————————————————————————————————————————————————————————————————————</span><br><span class="line"></span><br><span class="line">## 单个基因组eggNOG注释</span><br><span class="line">source activate py27</span><br><span class="line">.&#x2F;emapper.py  -i M_vent_MetaBat2_Bins_default.56.faa --cpu 30 -m diamond -o M_vent_MetaBat2_Bins_default.56.faa.annotation.tsv</span><br><span class="line">source deactivate</span><br><span class="line"></span><br><span class="line">## 单个基因组氢酶数据库注释</span><br><span class="line">nohup diamond blastp --db &#x2F;home&#x2F;houjialin&#x2F;data&#x2F;Database&#x2F;Hydrogen_Database&#x2F;Hydrogenase_Classification.DB -p 20 -q $ARGV[0]$bin --query-cover 50 -e 1e-100 -k 5 -o $bin_TIGR_out&amp;</span><br></pre></td></tr></table></figure></code></pre></li></ul><blockquote><ul><li><strong>需要Python 2.7 环境</strong></li><li>批量注释可以选择数据库：eggNOG或者氢酶数据库，默认同时注释</li><li>eggNOG注释比较慢，因此建议使用nohup，而HYdb比较小，注释较快</li><li>Hydb的结果自动提取Best hit</li></ul></blockquote><h3 id="使用hmmscan，注释TIRGfam，Pfam和CAYZme数据库"><a href="#使用hmmscan，注释TIRGfam，Pfam和CAYZme数据库" class="headerlink" title="使用hmmscan，注释TIRGfam，Pfam和CAYZme数据库"></a>使用hmmscan，注释TIRGfam，Pfam和CAYZme数据库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 批量注释TIGRfam，Pfam和CAYZme数据库，</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 注意每次注释基因组数量不要超过15个!</span></span></span><br><span class="line"></span><br><span class="line">nohup perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Batch_annotation/Batch_annotate_Pfam_TIGR_and_CAZYme_DB.pl ../Protein/1/ &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 批量提取BEST HIT</span></span></span><br><span class="line">perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Batch_annotation/Batch_Hmmscan_tblout_best_hit.pl</span><br><span class="line">_______________________________________________________________________________________</span><br><span class="line"><span class="meta">#</span><span class="bash"> TIGRfam数据库</span></span><br><span class="line">nohup hmmscan --domtblout L-vent_MaxBin.005.filtered.filtered.TIGRfamannotation -E 0.00001 --cpu 20 /home/houjialin/data/Database/TIGRFAM_database/HMM_lib/TIGRFAMs_14.0_HMM.LIB ../Proteins_Bins/L-vent_MaxBin.005.filtered.filtered.faa&amp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> Pfam数据库</span></span><br><span class="line">nohup hmmscan --domtblout M_vent_MetaBat2_Bins_default.86.filtered.filtered.Pfamannotation -E 0.00001 --cpu 20 /home/houjialin/data/Database/Pfam_database/Pfam-A.hmm ../Proteins_Bins/M_vent_MetaBat2_Bins_default.86.filtered.filtered.faa&amp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> CAYZme数据库</span></span><br><span class="line">nohup hmmscan --domtblout CAZYme.tbble -E 0.00001 --cpu 20 /home/houjialin/data/Database/CAZyme_database/dbCAN-fam-HMMs.txt ../Proteins_Bins/L-vent_MetaBat2_Bins_default.199.filtered.filtered.faa&amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">   #</span><span class="bash"> summary_CAzyme results</span></span><br><span class="line">   perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Batch_annotation/CAZyme_summary_results.pl</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>TIGRfam每个条目有单独的HMMmodel，可以用于快速比对寻找特定的目    标序列，具体路径：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/houjialin/data/Database/TIGRFAM_database/HMM</span><br></pre></td></tr></table></figure></li><li><p>注意区分hmmsearch 和 hmmscan的区别及使用方法：</p><ul><li>hmmsearch 是使用Hmm model搜寻蛋白序列库，query是Hmm model，适合寻找特定功能蛋白</li><li>hmmscan 是使用每条蛋白序列比对HMM model，query是每条蛋白系列，适合批量注释基因组</li></ul></li><li><p>Hmmscan貌似只能用单核，原因未知, hmmsearch 可以多核</p></li></ul></blockquote><h3 id="合并注释结果"><a href="#合并注释结果" class="headerlink" title="合并注释结果"></a>合并注释结果</h3><p>用于批量总结大量MAG的注释结果，首先针对每个MAG提取关键基因，生成单独的表；再将所有的MAG的注释结果汇总，最后基于既定的规则将汇总基因的注释结果总结成对于的代谢途径。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 总结每个MAG的注释结果，提取关键基因</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输入目录顺序：Protein/ eggNOG注释，TIGRpfam注释，Pfam注释</span></span><br><span class="line">  perl /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Batch_annotation/Summarize_annotation/1-Summarize_multiple_annotation_of_one_MAGs.pl  ../../Proteins_Bins/1/ ../eggNOG_annotation/ ../TIGRfam_annotation/ ../Pfam_annotation/</span><br><span class="line">  </span><br><span class="line"><span class="meta"> #</span><span class="bash"> 2. 将所有MAG的注释汇总成一张表</span></span><br><span class="line"> /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Batch_annotation/Summarize_annotation/2-Summarize_multiple_MAGs_annotation.pl ./</span><br><span class="line"> </span><br><span class="line"><span class="meta"> #</span><span class="bash"> 3. 将基因注释根据规则汇总成代谢途径，并用完整性表示</span></span><br><span class="line"> /home/houjialin/data/sdl/perl_script/hou_meta_pipeline/Batch_annotation/Summarize_annotation/3-Summarize_genes_into_metabolisms.pl</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>代谢关键酶注释表由banfield 文章修改整理</p><p><em>Potential for microbial H 2 and metal transformations associated with novel bacteria and archaea in deepterrestrial subsurface sediments</em></p></li><li><p>注意名称一致</p></li></ul></blockquote><hr><p>##Supplementary</p><p>###Canopy 的安装</p><ul><li><p>下载Canopy的<a href="https://bitbucket.org/HeyHo/mgs-canopy-algorithm/downloads/" target="_blank" rel="noopener">安装包</a>，上传至服务器</p></li><li><p>根据说明需要安装boots以及 <a href="http://www.boost.org/doc/libs/1_53_0/doc/html/program_options.html" target="_blank" rel="noopener">BOOST program options</a> library，服务器之前已经安过Boots，因此只需安装库即可</p></li><li><pre><code class="shell"><span class="meta">#</span><span class="bash"> 在boost安装文件夹下执行</span>./bootstrap.sh --with-libraries=program_options<span class="meta">#</span><span class="bash"> 成功后到</span>Building Boost.Build engine with toolset gcc... tools/build/src/engine/bin.linuxx86_64/b2Detecting Python version... 2.6Detecting Python root... /usrUnicode/ICU support for Boost.Regex?... not found.Generating Boost.Build configuration in project-config.jam...Bootstrapping is done. To build, run:    ./b2To adjust configuration, edit 'project-config.jam'.Further information:   - Command line help:     ./b2 --help   - Getting started guide:      http://www.boost.org/more/getting_started/unix-variants.html   - Boost.Build documentation:     http://www.boost.org/build/doc/html/index.html    # 编译，可以指定编译器，这里没有    ./b2    # 安装库,不知是否可以安装指定的库，这里升级了全部的库    ./b2 install    # 如果安装后想马上使用boost库进行编译    ldconfig    # 解压后进入文件canopy文件夹    make -f Makefile<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">###Construction HMM model</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;shell</span><br><span class="line"># Align the target sequence </span><br><span class="line">nohup clustalOmega -i acsB.txt -o acsB.aligned.faa --threads 20 --auto&amp;</span><br><span class="line"></span><br><span class="line"># Build a HMM model</span><br><span class="line">hmmbuild acsB.hmm acsB.aligned.faa</span><br><span class="line"></span><br><span class="line"># Search the AA sequences with hmm model</span><br><span class="line">hmmsearch acsB.hmm ..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;23_gene_prediction&#x2F;total_1000_protein.faa &gt; acsB.hmmsearch.table</span><br></pre></td></tr></table></figure></code></pre></li></ul><h3 id="Useful-command"><a href="#Useful-command" class="headerlink" title="Useful command"></a>Useful command</h3><ul><li><p>Diamond with coverage out put</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup diamond blastp -d ./Asgard_genome.faa -q target.protein.faa -p 20 -o DNA_enzymes_in_Asgard.diamond.tsv --more-sensitive -f 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send qcovhsp evalue bitscore &amp;</span><br></pre></td></tr></table></figure></li><li><p>预测16S 可变区</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vxtractor.pl -a -r .V1-V3. -h /software/Software/V-Xtractor/vxtractor/HMMs/SSU/bacteria/ -o out.fasta -c out.csv input.fasta</span><br></pre></td></tr></table></figure><blockquote><p>this will extract V1 through V3, for bacteria, from the file in.fasta and save the results to out.fasta, checking correct order of V1, V2, and V3.</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The paired-end metagenomic reads is packed as two compressed files, like 00_input-1.fq and 00_input-2.fq, after received from sequencing 
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>辨析 Sass 中的 Map 和 List</title>
    <link href="http://yoursite.com/2015/10/21/demo/"/>
    <id>http://yoursite.com/2015/10/21/demo/</id>
    <published>2015-10-21T02:34:12.000Z</published>
    <updated>2019-12-13T14:05:40.901Z</updated>
    
    <content type="html"><![CDATA[<p>如果你使用过 Sass 3.3 之前的版本，那么你一定对那段时光颇有感触，那时候没有现如今这么好的条件，那时候的 Map 还只能用多重列表（lists of list）来模拟。多重列表可以实现复杂数据的嵌套定义，但却不是以键值对的形式实现的，所有当我们需要获取其中特定的某一项时就会比较麻烦。Map 这种数据类型天生就是基于键值对的形式，非常便于组织数据。</p><p>自从可以使用 Map 之后，开发者们开始毫无顾忌地定义 Map 存储数据，比如断点宽度、颜色值、栅格布局等等响应式排版的细节，都被一股脑的塞进了 Map 中。</p><p>那么，有了 Map 之后，我们还有必要使用 List 吗？可能某些人会觉得为了保持向后兼容应该继续使用多重列表模拟 Map，因为可能有些开发者仍然在使用老版本的 Sass 编译器，但实际上，这是多此一举了，Sass 的版本通常由 <code>package.json</code> 或者其他同类型的项目配置文件所控制，往往只需一条命令（<code>gem update sass</code>）即可更新 Sass 的版本，因此基本上无需考虑对老版本的兼容问题。</p><a id="more"></a><p>使用多重列表替代 Map 的优势之一就是减少代码量。下面让我们来比较一下多种列表和 Map 的语法结构以及遍历方式。</p><h2 id="测试表格"><a href="#测试表格" class="headerlink" title="测试表格"></a>测试表格</h2><table><thead><tr><th>Variable</th><th>Description</th></tr></thead><tbody><tr><td><code>site</code></td><td>Sitewide information.</td></tr><tr><td><code>page</code></td><td>Page specific information and custom variables set in front-matter.</td></tr><tr><td><code>config</code></td><td>Site configuration</td></tr><tr><td><code>theme</code></td><td>Theme configuration. Inherits from site configuration.</td></tr><tr><td><code>_</code> (single underscore)</td><td><a href="http://lodash.com/" target="_blank" rel="noopener">Lodash</a> library</td></tr><tr><td><code>path</code></td><td>Path of current page</td></tr><tr><td><code>url</code></td><td>Full URL of current page</td></tr><tr><td><code>env</code></td><td>Environment variables</td></tr></tbody></table><h2 id="语法比较"><a href="#语法比较" class="headerlink" title="语法比较"></a>语法比较</h2><div class="note">    <h5>测试标题</h5>    <p>在下面的示例中，我创建了一个用于控制响应式布局的数据，该数据一共有四个断点，每一个断点都包含了 `min-width`、`max-width`、`font-size` 和 `line-height` 四个样式。</p></div><h4 id="Map-语法"><a href="#Map-语法" class="headerlink" title="Map 语法"></a>Map 语法</h4><p>下面就是使用 Map 存储的数据，具体来说，该 Map 中首先存储了四个用于标识断点的 Key，相对应的是保存具体属性值得 Value。虽然这种形式可读性更高，但是总体代码量却高达 26 行 450 个字符。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$breakpoint-map: (</span><br><span class="line">    small: (</span><br><span class="line">        min-width: null,</span><br><span class="line">        max-width: 479px,</span><br><span class="line">        base-font: 16px,</span><br><span class="line">        vertical-rhythm: 1.3</span><br><span class="line">    ),</span><br><span class="line">    medium: (</span><br><span class="line">        min-width: 480px,</span><br><span class="line">        max-width: 959px,</span><br><span class="line">        base-font: 18px,</span><br><span class="line">        vertical-rhythm: 1.414</span><br><span class="line">    ),</span><br><span class="line">    large: (</span><br><span class="line">        min-width: 960px,</span><br><span class="line">        max-width: 1099px,</span><br><span class="line">        base-font: 18px,</span><br><span class="line">        vertical-rhythm: 1.5</span><br><span class="line">    ),</span><br><span class="line">    xlarge: (</span><br><span class="line">        min-width: 1100px,</span><br><span class="line">        max-width: null,</span><br><span class="line">        base-font: 21px,</span><br><span class="line">        vertical-rhythm: 1.618</span><br><span class="line">    )</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h4 id="多重列表语法"><a href="#多重列表语法" class="headerlink" title="多重列表语法"></a>多重列表语法</h4><p>下面的多重列表存储了和上面 Map 同样的数据，在多重列表中没有 Key-Value 的对应关系，这意味着要想找到特定的值，必须使用遍历或 <code>nth()</code> 的方式来实现了。从另一个角度来看，多种列表又比 Map 的代码量小得多，总共只有六行 180 个字符。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$breakpoint-list: (</span><br><span class="line">    (small, null, 479px, 16px, 1.3),</span><br><span class="line">    (medium, 480px, 959px, 18px, 1.414),</span><br><span class="line">    (large, 960px, 1099px, 18px, 1.5),</span><br><span class="line">    (xlarge, 1100px, null, 21px, 1.618)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h2 id="遍历比较"><a href="#遍历比较" class="headerlink" title="遍历比较"></a>遍历比较</h2><div class="note info">    <h5>测试标题</h5>    <p>从上面简单地比较中可以粗略的看出，多种列表的代码量明显少于 Map。但是，如果我们需要遍历这些值得话，复杂度又是怎样的呢？</p></div><h4 id="遍历-Map"><a href="#遍历-Map" class="headerlink" title="遍历 Map"></a>遍历 Map</h4><p>我们可以使用如下的代码遍历 Map：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@each $label, $map in $breakpoint-map &#123;&#125;</span><br></pre></td></tr></table></figure><p>这里的变量 <code>$label</code> 和 <code>$map</code> 会随着对 <code>$breakpoint-map</code> 的遍历被动态地赋值，<code>$label</code> 将会被赋值为 <code>$breakpoint-map</code> 的 Key，而 <code>$map</code> 会被赋值为 <code>$breakpoint-map</code> 的 Value。为了在遍历过程中获取特定值，我们就需要使用 Sass 原生的 <code>map-get()</code> 函数，使用该函数需要传入两个参数：Map 的名字和求取的 Key，最后返回该 Map 中匹配该 Key 的 Value。</p><p>具体的做法就是使用 <code>@each</code> 遍历 Map，然后使用 <code>map-get()</code> 获取特定值，最终只需要六行代码 220 个字符即可完成整个遍历：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@each $label, $map in $breakpoint-map &#123;</span><br><span class="line">    $min-width: map-get($map, min-width);</span><br><span class="line">    $max-width: map-get($map, max-width);</span><br><span class="line">    $base-font: map-get($map, base-font);</span><br><span class="line">    $vertical-rhythm: map-get($map, vertical-rhythm);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="遍历多重列表"><a href="#遍历多重列表" class="headerlink" title="遍历多重列表"></a>遍历多重列表</h4><p>遍历多重列表不必像遍历 Map 一样动态获取到 Map 后再使用 <code>map-get()</code> 函数取特定值，直接遍历一遍即可获得特定值。</p><p>因为多种列表内层的每一个列表结构相同，都有按照相同顺序排列的五个值，所以我们可以持续遍历每个值并赋值给特定的变量。无需调用 <code>map-get()</code>，直接引用这些变量即可进行赋值等裸机操作。最终遍历多重列表只使用了两行代码 100 个字符：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@each $label, $min-width, $max-width, $base-font, $vertical-rhythm in $breakpoint-list &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="慎用多重列表"><a href="#慎用多重列表" class="headerlink" title="慎用多重列表"></a>慎用多重列表</h2><div class="note warning">    <h5>测试标题</h5>    <p>经过上述的比对，看起来多重列表各方面都在碾压 Map，实则不然，Sass 中添加 Map 有一条非常重要的原因就是：Key-Value 的映射关系。</p></div><h4 id="遗漏键值"><a href="#遗漏键值" class="headerlink" title="遗漏键值"></a>遗漏键值</h4><p>如果要使用多重列表，那么就必须保证自己非常熟悉多重列表内部的每一项所代表的意义。下面我们举个例子，来看看遗漏了某些值的情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$breakpoint-list: (</span><br><span class="line">    (small, null, 479px, 16px, 1.3),</span><br><span class="line">    (medium, 480px, 959px, 18px, 1.414),</span><br><span class="line">    (large, 960px, 1099px, 18px, 1.5),</span><br><span class="line">    (xlarge, 1100px, 21px, 1.618)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">p &#123;</span><br><span class="line">    @each $label, $min-width, $max-width, $base-font, $vertical-rhythm in $breakpoint-list &#123;</span><br><span class="line">        @if $min-width &#123;</span><br><span class="line">            @include breakpoint( $min-width ) &#123;</span><br><span class="line">                font-size: $base-font;</span><br><span class="line">                line-height: $vertical-rhythm;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; @else &#123;</span><br><span class="line">            font-size: $base-font;</span><br><span class="line">            line-height: $vertical-rhythm;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当我们尝试运行这段代码时，结果肯定是错误地，因为在 <code>$breakpoint-list</code> 的最后一行，<code>xlarge</code> 被赋值给了 <code>$label</code>，<code>1100px</code> 被赋值给了 <code>$min-width</code>，<code>21px</code> 被赋值给了 <code>$max-width</code>, <code>1.618</code> 被赋值给了 <code>$base-font</code>，最终导致 <code>$vertical-rhythm</code> 没有被赋值，结果就是 <code>font-size</code> 的属性值是错的，<code>line-height</code> 的属性值是空的。此外，Sass 还不会对此抛出错误，导致我们无从知晓错误所在。</p><p>如果我们使用 Map 来代替这里的多重列表，那么使用 <code>map-get()</code> 函数即使遇见空值也能正确获得想要的结果。这就是值得我们慎重思考的地方：多种列表虽然简单快速，但是丧失了 Map 中的容错能力和快速取值能力。</p><h4 id="查找特定列表"><a href="#查找特定列表" class="headerlink" title="查找特定列表"></a>查找特定列表</h4><p>在多重列表中查找特定列表简直就是一种折磨。如果使用 Map，那么配合 <code>map-get()</code> 函数可以快速定位到特定子 Map：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$medium-map: map-get($maps, medium);</span><br></pre></td></tr></table></figure><p>但如果要获取多种列表 <code>medium</code> 列表，麻烦可就大了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@function get-list($label) &#123;</span><br><span class="line">    @each $list in $breakpoint-list &#123;</span><br><span class="line">        @if nth($list, 1) &#x3D;&#x3D; $label &#123;</span><br><span class="line">            @return $list;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    @return null;</span><br><span class="line">&#125;</span><br><span class="line">$medium-list: get-list(medium);</span><br></pre></td></tr></table></figure><p>这段代码的逻辑就是遍历整个多重列表，知道找到第一个匹配项，然后返回，如果一直没有找到匹配项，就一直遍历到末尾，然后返回 <code>null</code>。这实际上就是手工实现了 <code>map-get()</code> 的逻辑。</p><h4 id="缺少原生的-Map-函数"><a href="#缺少原生的-Map-函数" class="headerlink" title="缺少原生的 Map 函数"></a>缺少原生的 Map 函数</h4><p>Sass 提供了诸多的原生函数用于处理 Map 数据类型，但是多重列表是没法调用这些函数的，比如，使用 <code>map-merge()</code> 可以合并两个 Map，如果两个 Map 有相同的值，则取第二个 Map 的值为最终值。当然你也可以在多重列表中使用 <code>join()</code> 或 <code>append()</code> 来增加新列表，从而模拟出 <code>map-merge()</code> 的效果。</p><p>另一个实用的 Map 函数就是 <code>map-has-key()</code>，对于依赖 <code>map-get()</code> 的自定义函数来说，<code>map-has-key()</code> 可以用来验证特定的 Key 是否存在。但在列表中是完全没有相似的方法。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><div class="note unreleased">    <h5>Test Title</h5>    <p>相比起列表来说，Key-Value 模型的 Map 显然更有力量，原生的 Sass Map 函数更是提供了强力的数据查找和验证工具。</p></div><p>虽然多重列表代码量少，但并不能像 Map 一样进行错误检查或验证参数。在大多数时候，相比较多重列表而言，我相信 Map 是更好的选择。如果是为了更少的代码量和其他简单地调用，那么我偶尔会用用多重列表，但是从项目的宏观控制和数据存储方面显然更优秀。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果你使用过 Sass 3.3 之前的版本，那么你一定对那段时光颇有感触，那时候没有现如今这么好的条件，那时候的 Map 还只能用多重列表（lists of list）来模拟。多重列表可以实现复杂数据的嵌套定义，但却不是以键值对的形式实现的，所有当我们需要获取其中特定的某一项时就会比较麻烦。Map 这种数据类型天生就是基于键值对的形式，非常便于组织数据。&lt;/p&gt;
&lt;p&gt;自从可以使用 Map 之后，开发者们开始毫无顾忌地定义 Map 存储数据，比如断点宽度、颜色值、栅格布局等等响应式排版的细节，都被一股脑的塞进了 Map 中。&lt;/p&gt;
&lt;p&gt;那么，有了 Map 之后，我们还有必要使用 List 吗？可能某些人会觉得为了保持向后兼容应该继续使用多重列表模拟 Map，因为可能有些开发者仍然在使用老版本的 Sass 编译器，但实际上，这是多此一举了，Sass 的版本通常由 &lt;code&gt;package.json&lt;/code&gt; 或者其他同类型的项目配置文件所控制，往往只需一条命令（&lt;code&gt;gem update sass&lt;/code&gt;）即可更新 Sass 的版本，因此基本上无需考虑对老版本的兼容问题。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="css" scheme="http://yoursite.com/tags/css/"/>
    
  </entry>
  
</feed>
